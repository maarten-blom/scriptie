{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import networkx as nx\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import PyPDF2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import io\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using PyMuPDF (fitz).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdf_path, min_size=(50, 50), min_aspect_ratio=0.5, max_aspect_ratio=2.0):\n",
    "    \"\"\"\n",
    "    Extracts images from a PDF file using PyMuPDF (fitz) and returns a list of unique images.\n",
    "    Filters out small and irrelevant images based on size and aspect ratio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        images = []\n",
    "        image_hashes = set()\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                xref = img[0]\n",
    "                base_image = pdf_document.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")  # Ensure image is in RGB mode\n",
    "                \n",
    "                # Calculate hash of the image\n",
    "                image_hash = hashlib.md5(image.tobytes()).hexdigest()\n",
    "                \n",
    "                # Filter images based on size, aspect ratio, and uniqueness\n",
    "                if image_hash not in image_hashes:\n",
    "                    width, height = image.size\n",
    "                    aspect_ratio = width / height\n",
    "                    if (width >= min_size[0] and height >= min_size[1] and \n",
    "                        min_aspect_ratio <= aspect_ratio <= max_aspect_ratio):\n",
    "                        images.append(image)\n",
    "                        image_hashes.add(image_hash)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from {pdf_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(images, model, transform):\n",
    "    \"\"\"\n",
    "    Extracts features from a list of images using a pre-trained ResNet model.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for image in images:\n",
    "        image = transform(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            feature = model(image)\n",
    "        features.append(feature.squeeze().numpy())\n",
    "    if features:\n",
    "        return np.mean(features, axis=0)\n",
    "    else:\n",
    "        return np.zeros((2048,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_pdf_files(base_path, model, transform):\n",
    "    df = pd.DataFrame(columns=['paper_text', 'slide_text', 'paper_image_features', 'slide_image_features', 'paper_name', 'slide_name'])\n",
    "\n",
    "    for folder_num in tqdm(range(4984)):\n",
    "        folder_path = os.path.join(base_path, str(folder_num))\n",
    "        slide_name = None\n",
    "        paper_name = None\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                if \"slide\" in file_name or \"Slide\" in file_name:\n",
    "                    slide_name = file_name\n",
    "                else:\n",
    "                    paper_name = file_name\n",
    "\n",
    "        slide_pdf_path = os.path.join(folder_path, slide_name)\n",
    "        paper_pdf_path = os.path.join(folder_path, paper_name)\n",
    "\n",
    "        slide_text = extract_text_from_pdf(slide_pdf_path)\n",
    "        paper_text = extract_text_from_pdf(paper_pdf_path)\n",
    "\n",
    "        slide_images = extract_images_from_pdf(slide_pdf_path)\n",
    "        paper_images = extract_images_from_pdf(paper_pdf_path)\n",
    "\n",
    "        slide_image_features = extract_features_from_images(slide_images, model, transform)\n",
    "        paper_image_features = extract_features_from_images(paper_images, model, transform)\n",
    "\n",
    "        df.loc[folder_num] = [paper_text, slide_text, paper_image_features, slide_image_features, paper_name, slide_name]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the base path of your dataset\n",
    "base_path = \"dataset\"\n",
    "\n",
    "# Initialize the ResNet model and the transform\n",
    "model = resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove the final classification layer\n",
    "model.eval()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Process the PDF files and create the dataframe\n",
    "df = process_pdf_files(base_path, model, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.lower()\n",
    "    if text:\n",
    "        return text\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "df.paper_text = df.paper_text.apply(clean)\n",
    "df.slide_text = df.slide_text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine paper and slide content for TF-IDF vectorization\n",
    "combined_content = df.paper_text.tolist() + df.slide_text.tolist()\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
    "X = vectorizer.fit_transform(combined_content)\n",
    "\n",
    "# Split the TF-IDF matrix back into papers and slides\n",
    "X_papers = X[:len(df)]\n",
    "X_slides = X[len(df):]\n",
    "\n",
    "text_similarity_matrix = cosine_similarity(X_papers, X_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_papers = np.stack(df.paper_image_features.values)\n",
    "image_features_slides = np.stack(df.slide_image_features.values)\n",
    "\n",
    "image_similarity_matrix = cosine_similarity(image_features_papers, image_features_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Combined(and Individual) Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actual):\n",
    "    predictions = np.array(predictions)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    correct_predictions = np.sum(predictions == actual)\n",
    "    accuracy = correct_predictions / len(actual) * 100\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Text Weight', 'Image Weight', 'Accuracy'])\n",
    "\n",
    "for i in range(11):\n",
    "    text_weight = i / 10.0\n",
    "    image_weight = 1 - text_weight\n",
    "    \n",
    "\n",
    "    combined_similarity_matrix = (text_weight * text_similarity_matrix) + (image_weight * image_similarity_matrix)\n",
    "    \n",
    "    slide_to_paper_mapping = np.argmax(combined_similarity_matrix, axis=0)\n",
    "    \n",
    "    predicted = pd.DataFrame({\n",
    "        'slides': df['slide_name'],\n",
    "        'PredictedPaperDocname': df['paper_name'].iloc[slide_to_paper_mapping].values\n",
    "    })\n",
    "    \n",
    "    accuracy = calculate_accuracy(predicted['PredictedPaperDocname'], df['paper_name'])\n",
    "    \n",
    "    results_df = results_df.append({\n",
    "        'Text Weight': text_weight,\n",
    "        'Image Weight': image_weight,\n",
    "        'Accuracy': accuracy\n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again but filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_filtered = pd.DataFrame(columns=['Text Weight', 'Image Weight', 'Accuracy'])\n",
    "\n",
    "for i in range(11):\n",
    "    text_weight = i / 10.0\n",
    "    image_weight = 1 - text_weight\n",
    "\n",
    "    combined_similarity_matrix = (text_weight * text_similarity_matrix) + (image_weight * image_similarity_matrix)\n",
    "    \n",
    "    slide_to_paper_mapping = np.argmax(combined_similarity_matrix, axis=0)\n",
    "    predictions = pd.DataFrame({\n",
    "        'slides': df['slide_name'],\n",
    "        'PredictedPaperDocname': df['paper_name'].iloc[slide_to_paper_mapping].values\n",
    "    })\n",
    "    actual = pd.DataFrame({\n",
    "        'slides': df['slide_name'],\n",
    "        'PredictedPaperDocname': df['paper_name']\n",
    "    })\n",
    "\n",
    "    usable_images_filter = df['paper_image_features'].apply(lambda x: not np.all(x == 0))\n",
    "    filtered_predictions = predictions[usable_images_filter]\n",
    "    filtered_actual = actual[usable_images_filter]\n",
    "    \n",
    "    accuracy = calculate_accuracy(filtered_predictions['PredictedPaperDocname'], filtered_actual['PredictedPaperDocname'])\n",
    "    \n",
    "    results_df = results_df.append({\n",
    "        'Text Weight': text_weight,\n",
    "        'Image Weight': image_weight,\n",
    "        'Accuracy': accuracy\n",
    "    }, ignore_index=True)\n",
    "\n",
    "\n",
    "print(results_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
